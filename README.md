# ğŸš€ DataOps Pipeline - Bronze, Silver, Gold

Pipeline completo de dados com arquitetura em camadas, orquestraÃ§Ã£o Airflow e dashboard em tempo real.

## ğŸ“Š Arquitetura

```
Label Studio (NER Annotations)
         â†“
    Bronze Layer (Raw JSON)
         â†“
    Silver Layer (Clean + NER Extraction)
         â†“
    Gold Layer (Aggregations + KPIs)
         â†“
    Streamlit Dashboard
```

## ğŸ› ï¸ Stack TecnolÃ³gica

- **OrquestraÃ§Ã£o**: Apache Airflow (event-driven com sensores deferrÃ¡veis)
- **Storage**: MinIO (S3-compatible, 3 camadas)
- **TransformaÃ§Ã£o**: Python + Pandas
- **AnotaÃ§Ã£o**: Label Studio (NER)
- **VisualizaÃ§Ã£o**: Streamlit
- **Infraestrutura**: Docker + Docker Compose
- **Banco de Dados**: PostgreSQL

## âš¡ Quick Start

> **ğŸ†• Primeira vez usando?** Veja [INSTALACAO_AMBIENTE.md](INSTALACAO_AMBIENTE.md) para instalaÃ§Ã£o completa do zero (Conda + UV + Docker)

### 1. Clone o repositÃ³rio
```bash
git clone <URL>
cd Dataops
```

### 2. Configure o ambiente Python (opcional - local)
```bash
# Criar ambiente conda
conda create -n dataops python=3.10 -y
conda activate dataops

# Instalar dependÃªncias com UV
uv sync --directory enviroments
```

### 3. Configure as credenciais
```bash
cp .env.example .env
# Edite .env com suas credenciais
```

### 4. Inicie o ambiente Docker
```bash
docker-compose up -d
```

### 5. Acesse os serviÃ§os
- **Airflow**: http://localhost:8080 (airflow/airflow)
- **Label Studio**: http://localhost:8001 (label_ops@gmail.com/dataops@123)
- **MinIO**: http://localhost:9001 (veja .env)
- **Dashboard**: http://localhost:8501

## ğŸ“– DocumentaÃ§Ã£o Completa

### ğŸ¯ Para ComeÃ§ar
- **[INSTALACAO_AMBIENTE.md](INSTALACAO_AMBIENTE.md)** ğŸ†• **DO ZERO** - InstalaÃ§Ã£o completa do ambiente
  - Instalar Conda/Miniconda
  - Criar ambiente Python 3.10
  - Instalar UV (gerenciador de dependÃªncias)
  - Instalar Docker + Docker Compose
  - Configurar e executar todo o pipeline

- **[SETUP_COMPLETO.md](SETUP_COMPLETO.md)** â­ **QUICK START** - Guia rÃ¡pido (se jÃ¡ tem ambiente)
  - PrÃ©-requisitos
  - InstalaÃ§Ã£o
  - **ConfiguraÃ§Ã£o do Legacy Token do Label Studio**
  - ExecuÃ§Ã£o do pipeline
  - Troubleshooting

### ğŸ“š Guias EspecÃ­ficos
- **[COMECE_AQUI.md](COMECE_AQUI.md)** - Quick start de 5 minutos
- **[DOCKER_COMPOSE_SETUP.md](DOCKER_COMPOSE_SETUP.md)** - Docker Compose detalhado
- **[PROXIMO_TESTE.md](PROXIMO_TESTE.md)** - Como testar o pipeline

### ğŸ”§ DocumentaÃ§Ã£o TÃ©cnica
- **[RESUMO_CORRECOES_IMPLEMENTADAS.md](RESUMO_CORRECOES_IMPLEMENTADAS.md)** - Detalhes tÃ©cnicos
- **[FIXES_NER_EXTRACTION.md](FIXES_NER_EXTRACTION.md)** - NER extraction troubleshooting
- **[STREAMLIT_NETWORK_FIX.md](STREAMLIT_NETWORK_FIX.md)** - Rede Docker e seguranÃ§a

### ğŸ“‹ ReferÃªncia RÃ¡pida
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - Comandos Ãºteis
- **[VISAO_GERAL_PROJETO.md](VISAO_GERAL_PROJETO.md)** - VisÃ£o geral completa

## âš ï¸ IMPORTANTE: Label Studio Legacy Token

Este pipeline requer o **Legacy Token** do Label Studio, nÃ£o o Access Token (JWT).

**Como configurar e obter**:

1. **Acesse Label Studio**: http://localhost:8001
2. **Primeiro acesso**: Crie conta com `label_ops@gmail.com` / `dataops@123`
   - Ou use credenciais padrÃ£o: `admin@localhost.com` / `123456`

3. **Habilitar Legacy Tokens (evitar expiraÃ§Ã£o)**:
   - Clique em **"Organization"** (menu lateral)
   - Clique em **"API Tokens Settings"**
   - âœ… Deixe APENAS a flag **"Legacy tokens"** marcada
   - âŒ Desmarque as outras opÃ§Ãµes
   - Clique em **"Save"**

4. **Copiar o token**:
   - Clique no Ã­cone do usuÃ¡rio (canto superior direito)
   - **Account & Settings**
   - Procure por **"Legacy API Token"**
   - Copie o token (40 caracteres hexadecimais)
   - Cole no `.env`: `LABELSTUDIO_TOKEN=seu_token_aqui`

Ver detalhes completos em **[SETUP_COMPLETO.md](SETUP_COMPLETO.md) - Passo 4.3**

## ğŸ“Š Dataset do Projeto

O projeto utiliza um dataset de transaÃ§Ãµes comerciais com anotaÃ§Ãµes NER.

**ğŸ“¥ Baixar dataset**:
```
https://drive.google.com/drive/folders/1WFkw54HojR1y_Io26_cNV5ni3888I2FZ?usp=sharing
```

**ConteÃºdo**:
- TransaÃ§Ãµes comerciais (cliente, produto, valor, etc.)
- AnotaÃ§Ãµes NER jÃ¡ realizadas
- Pronto para importaÃ§Ã£o no Label Studio

**Como usar**:
1. Baixe o dataset do Google Drive
2. Importe no Label Studio (Project ID 4)
3. Execute o pipeline via Airflow
4. Visualize resultados no Dashboard

Ver instruÃ§Ãµes completas em **[INSTALACAO_AMBIENTE.md](INSTALACAO_AMBIENTE.md) - Parte 8.6**

## ğŸ¯ Principais Features

âœ… **Event-Driven Architecture** - Airflow detecta novos arquivos automaticamente
âœ… **3 Camadas (Bronze/Silver/Gold)** - Arquitetura Medallion
âœ… **NER Extraction** - Named Entity Recognition via Label Studio
âœ… **Debug AutomÃ¡tico** - Logs detalhados de extraÃ§Ã£o
âœ… **SeguranÃ§a** - Credenciais em variÃ¡veis de ambiente
âœ… **Auto-detecÃ§Ã£o de Ambiente** - Funciona local e Docker
âœ… **Dashboard Real-time** - Streamlit com atualizaÃ§Ã£o automÃ¡tica
âœ… **DocumentaÃ§Ã£o Completa** - 10+ guias tÃ©cnicos

## ğŸ“ˆ MÃ©tricas

- **950+ registros/dia** processados
- **8 KPIs** prÃ©-calculados
- **3 camadas** de storage
- **0 credenciais** hardcoded
- **100% containerizado**

## ğŸ”§ Desenvolvimento

### Executar localmente (fora do Docker)

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Executar pipeline
python -m scripts_pipeline.clean_buckets
python -m scripts_pipeline.insert_bronze
python -m scripts_pipeline.transform_silver
python -m scripts_pipeline.aggregate_gold

# Ver diagnÃ³stico
python diagnose_data_flow.py

# Visualizar dashboard (apÃ³s dados subirem para camada Gold)
streamlit run streamlit\dashboard.py
```

> **ğŸ’¡ NOTA**: Se estiver usando Docker, o dashboard jÃ¡ estÃ¡ rodando automaticamente em http://localhost:8501

### Estrutura de DiretÃ³rios

```
Dataops/
â”œâ”€â”€ dags/                    # Airflow DAGs
â”‚   â”œâ”€â”€ sensors/            # Sensores customizados
â”‚   â””â”€â”€ env_config.py       # ConfiguraÃ§Ã£o segura
â”œâ”€â”€ scripts_pipeline/        # Scripts de transformaÃ§Ã£o
â”‚   â”œâ”€â”€ insert_bronze.py    # IngestÃ£o
â”‚   â”œâ”€â”€ transform_silver.py # Limpeza + NER
â”‚   â””â”€â”€ aggregate_gold.py   # AgregaÃ§Ãµes
â”œâ”€â”€ streamlit/              # Dashboard
â”‚   â””â”€â”€ dashboard.py
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o
â”œâ”€â”€ .env.example           # Template de configuraÃ§Ã£o
â””â”€â”€ docs/                   # DocumentaÃ§Ã£o completa
```

## ğŸ› Troubleshooting

### Container nÃ£o inicia
```bash
docker-compose logs <container_name>
```

### Erro "Failed to resolve 'minio'"
âœ… JÃ¡ corrigido! O sistema detecta automaticamente o ambiente.

### Label Studio - 401 Unauthorized
Certifique que estÃ¡ usando **Legacy Token**, nÃ£o Access Token.

Ver mais em **[SETUP_COMPLETO.md](SETUP_COMPLETO.md) - Troubleshooting**

## ğŸ“Š Fluxo de Dados

1. **IngestÃ£o**: Label Studio API â†’ JSON estruturado â†’ MinIO Bronze
2. **TransformaÃ§Ã£o**: Bronze â†’ Limpeza + NER extraction â†’ MinIO Silver
3. **AgregaÃ§Ã£o**: Silver â†’ KPIs + AgregaÃ§Ãµes â†’ MinIO Gold
4. **VisualizaÃ§Ã£o**: Gold â†’ Streamlit Dashboard

## ğŸ“ Conceitos Aplicados

- **DataOps**: OrquestraÃ§Ã£o, monitoramento, versionamento
- **Medallion Architecture**: Bronze (raw) â†’ Silver (clean) â†’ Gold (curated)
- **Event-Driven**: Processamento reativo a eventos
- **NER (Named Entity Recognition)**: ExtraÃ§Ã£o de entidades nomeadas
- **ContainerizaÃ§Ã£o**: Docker, isolamento, portabilidade
- **Security**: Credenciais em variÃ¡veis de ambiente

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido como trabalho de conclusÃ£o de disciplina.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:
1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ Suporte

- **DocumentaÃ§Ã£o**: Ver pasta `docs/` ou arquivos `.md` na raiz
- **Issues**: Abra uma issue no GitHub

---

**Desenvolvido com** â¤ï¸ **usando Python, Airflow, Docker e muito cafÃ©** â˜•

â­ **Se este projeto foi Ãºtil, deixe uma estrela!**
