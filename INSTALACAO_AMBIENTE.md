# ğŸ InstalaÃ§Ã£o Completa do Ambiente - Do Zero ao Pipeline Funcionando

Este guia cobre desde a instalaÃ§Ã£o do Conda atÃ© a execuÃ§Ã£o completa do pipeline.

## ğŸ“‹ PrÃ©-requisitos

- **Sistema Operacional**: Windows 10/11, Linux ou macOS
- **RAM**: MÃ­nimo 8GB (recomendado 16GB)
- **EspaÃ§o em Disco**: MÃ­nimo 10GB livres
- **ConexÃ£o com Internet**: Para download de dependÃªncias

---

## ğŸ”§ Parte 1: Instalar Conda (se nÃ£o tiver)

### OpÃ§Ã£o A: Instalar Miniconda (Recomendado - Mais leve)

#### Windows:
1. **Baixe o instalador**:
   - Acesse: https://docs.conda.io/en/latest/miniconda.html
   - Baixe: `Miniconda3 Windows 64-bit`

2. **Execute o instalador**:
   - Duplo clique no arquivo `.exe` baixado
   - Aceite os termos
   - Escolha "Just Me" (recomendado)
   - Deixe o caminho padrÃ£o: `C:\Users\<seu_usuario>\miniconda3`
   - **IMPORTANTE**: Marque âœ… "Add Miniconda3 to my PATH environment variable"
   - Clique em "Install"

3. **Verifique a instalaÃ§Ã£o**:
   ```bash
   # Abra um novo terminal (PowerShell ou CMD)
   conda --version
   # Esperado: conda 23.x.x ou superior
   ```

#### Linux/Mac:
```bash
# Baixar instalador
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# Executar instalador
bash Miniconda3-latest-Linux-x86_64.sh

# Seguir instruÃ§Ãµes no terminal
# Aceitar licenÃ§a: yes
# Confirmar localizaÃ§Ã£o: Enter
# Inicializar conda: yes

# Recarregar shell
source ~/.bashrc

# Verificar
conda --version
```

### OpÃ§Ã£o B: Instalar Anaconda (Completo - Mais pesado)

1. Acesse: https://www.anaconda.com/products/distribution
2. Baixe o instalador para seu sistema operacional
3. Execute e siga as instruÃ§Ãµes
4. Verifique: `conda --version`

---

## ğŸ Parte 2: Criar Ambiente Conda

### 2.1 Criar ambiente com Python 3.10

```bash
# Criar ambiente conda chamado "dataops" com Python 3.10
conda create -n dataops python=3.10 -y

# Aguarde o download e instalaÃ§Ã£o (pode demorar 2-5 minutos)
```

### 2.2 Ativar o ambiente

```bash
# Windows (CMD ou PowerShell)
conda activate dataops

# Linux/Mac
conda activate dataops
```

**VocÃª saberÃ¡ que funcionou quando ver**:
```
(dataops) C:\Users\seu_usuario>
          â†‘
    Ambiente ativado!
```

### 2.3 Verificar Python instalado

```bash
python --version
# Esperado: Python 3.10.x
```

---

## ğŸ“¦ Parte 3: Instalar UV (Gerenciador de DependÃªncias)

UV Ã© um gerenciador de pacotes Python extremamente rÃ¡pido, escrito em Rust.

### 3.1 Instalar UV

#### Windows (PowerShell):
```bash
# MÃ©todo 1: Via pip
pip install uv

# OU MÃ©todo 2: Via instalador oficial
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### Linux/Mac:
```bash
# MÃ©todo 1: Via pip
pip install uv

# OU MÃ©todo 2: Via curl
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 3.2 Verificar instalaÃ§Ã£o

```bash
uv --version
# Esperado: uv 0.x.x ou superior
```

---

## ğŸ”Œ Parte 4: Instalar DependÃªncias do Projeto

### 4.1 Navegar atÃ© o diretÃ³rio do projeto

```bash
cd d:\Projetos\Dataops
```

### 4.2 Instalar dependÃªncias com UV

```bash
# Sincronizar ambiente com as dependÃªncias do pyproject.toml
uv sync --directory enviroments

# OU se preferir usar pip tradicional (mais lento)
cd enviroments
pip install -e .
cd ..
```

**O que acontece**:
- UV lÃª `enviroments/pyproject.toml`
- Baixa e instala todas as dependÃªncias listadas:
  - pandas, numpy, sqlalchemy
  - Apache Airflow + providers
  - MinIO, boto3
  - Streamlit, Plotly
  - Label Studio SDK
  - E muitas outras...

**Tempo estimado**: 3-10 minutos (dependendo da conexÃ£o)

### 4.3 Verificar instalaÃ§Ã£o das dependÃªncias principais

```bash
# Verificar Airflow
python -c "import airflow; print(f'Airflow {airflow.__version__}')"

# Verificar Pandas
python -c "import pandas; print(f'Pandas {pandas.__version__}')"

# Verificar MinIO
python -c "import minio; print('MinIO SDK instalado!')"

# Verificar Streamlit
streamlit --version
```

---

## ğŸ³ Parte 5: Instalar Docker e Docker Compose

### 5.1 Instalar Docker Desktop

#### Windows/Mac:
1. **Baixe Docker Desktop**:
   - Windows: https://www.docker.com/products/docker-desktop
   - Mac: https://www.docker.com/products/docker-desktop

2. **Execute o instalador**:
   - Duplo clique no arquivo baixado
   - Siga as instruÃ§Ãµes padrÃ£o
   - **Windows**: Certifique-se de habilitar WSL 2 se solicitado

3. **Inicie o Docker Desktop**:
   - Abra o aplicativo Docker Desktop
   - Aguarde aparecer "Docker is running"

#### Linux:
```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Adicionar seu usuÃ¡rio ao grupo docker
sudo usermod -aG docker $USER

# Reiniciar sessÃ£o ou executar
newgrp docker

# Instalar Docker Compose
sudo apt-get install docker-compose-plugin
```

### 5.2 Verificar instalaÃ§Ã£o

```bash
# Verificar Docker
docker --version
# Esperado: Docker version 20.10.x ou superior

# Verificar Docker Compose
docker-compose --version
# Esperado: Docker Compose version v2.x.x ou superior

# Teste bÃ¡sico
docker run hello-world
# Esperado: mensagem "Hello from Docker!"
```

---

## ğŸ” Parte 6: Configurar VariÃ¡veis de Ambiente

### 6.1 Criar arquivo .env

```bash
# Copiar template
cp .env.example .env
```

### 6.2 Editar .env

Abra o arquivo `.env` e preencha com suas credenciais:

```bash
# Windows
notepad .env

# Linux/Mac
nano .env
```

**ConteÃºdo mÃ­nimo do .env**:
```env
# ========================================
# MinIO Configuration
# ========================================
MINIO_ACCESS_KEY=admin_dataops
MINIO_SECRET_KEY=SenhaSegura123!MinIO

# ========================================
# Label Studio Configuration
# ========================================
LABELSTUDIO_TOKEN=  # VocÃª vai preencher isso no Passo 8
LABELSTUDIO_PROJECT=4

# ========================================
# Airflow Configuration
# ========================================
AIRFLOW_UID=50000
```

**Salve o arquivo** (Ctrl+S no Notepad, Ctrl+X no nano)

---

## ğŸš€ Parte 7: Iniciar Containers Docker

### 7.1 Build das imagens

```bash
# Certifique-se de estar no diretÃ³rio do projeto
cd d:\Projetos\Dataops

# Build de todas as imagens
docker-compose build

# Tempo estimado: 5-15 minutos na primeira vez
```

### 7.2 Iniciar todos os serviÃ§os

```bash
# Iniciar em background
docker-compose up -d

# Acompanhar logs (opcional)
docker-compose logs -f
```

### 7.3 Verificar status

```bash
# Verificar containers
docker-compose ps
```

**Esperado**:
```
NAME                    STATUS
airflow-webserver       Up (healthy)
airflow-scheduler       Up (healthy)
airflow-triggerer       Up (healthy)
minio                   Up (healthy)
label-studio            Up (healthy)
streamlit-dashboard     Up (healthy)
```

> **â±ï¸ Aguarde**: Pode demorar 2-3 minutos atÃ© todos ficarem "healthy"

---

## ğŸ·ï¸ Parte 8: Configurar Label Studio e Obter Token

### 8.1 Acessar Label Studio

```
http://localhost:8001
```

### 8.2 Criar conta (primeiro acesso)

1. **Clique em "Sign Up"**
2. **Preencha**:
   - Email: `label_ops@gmail.com`
   - Password: `dataops@123`
   - Confirm Password: `dataops@123`
3. **Clique em "Create Account"**

### 8.3 Configurar e Obter Legacy Token

**Passo A: Habilitar Legacy Tokens (evitar expiraÃ§Ã£o)**

1. **No Label Studio, clique em "Organization"** (menu lateral esquerdo)
2. **Clique em "API Tokens Settings"**
3. **Desmarque todas as flags EXCETO "Legacy tokens"**
   - âœ… Deixe APENAS "Legacy tokens" marcado
   - âŒ Desmarque as outras opÃ§Ãµes (isso evita que o token expire)
4. **Clique em "Save"**

**Passo B: Copiar o Legacy Token**

1. **Clique no Ã­cone do usuÃ¡rio** (canto superior direito)
2. **Clique em "Account & Settings"**
3. **Procure "Legacy API Token"**
4. **Copie o token** (40 caracteres hexadecimais)

> **ğŸ’¡ IMPORTANTE**: A configuraÃ§Ã£o em "Organization > API Tokens Settings" garante que o token nÃ£o expire automaticamente.

### 8.4 Atualizar .env com token

```bash
# Editar .env novamente
notepad .env  # Windows
nano .env     # Linux/Mac
```

Cole o token:
```env
LABELSTUDIO_TOKEN=a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0
```

### 8.5 Reiniciar containers

```bash
docker-compose restart airflow-scheduler
docker-compose restart airflow-webserver
docker-compose restart streamlit
```

### 8.6 Importar Dataset do Projeto

O projeto utiliza um dataset de transaÃ§Ãµes comerciais jÃ¡ anotado com entidades NER.

**ğŸ“Š Dataset disponÃ­vel em**:
```
https://drive.google.com/drive/folders/1WFkw54HojR1y_Io26_cNV5ni3888I2FZ?usp=sharing
```

**Como importar**:

1. **Baixe o dataset** do Google Drive
2. **Acesse Label Studio**: http://localhost:8001
3. **Abra o projeto** (ID 4)
4. **Clique em "Import"**
5. **Selecione os arquivos JSON** baixados
6. **Clique em "Import"**

**O que contÃ©m o dataset**:
- TransaÃ§Ãµes comerciais com dados de clientes, produtos e valores
- AnotaÃ§Ãµes NER jÃ¡ realizadas (cliente, produto, valor, etc.)
- Dados prontos para processamento pelo pipeline

> **ğŸ’¡ IMPORTANTE**: ApÃ³s importar o dataset, vocÃª pode executar o pipeline para processar esses dados atravÃ©s das camadas Bronze â†’ Silver â†’ Gold.

---

## âœ… Parte 9: Verificar InstalaÃ§Ã£o Completa

### 9.1 Verificar ambiente Python

```bash
# Ambiente ativado?
conda env list
# Deve mostrar * ao lado de "dataops"

# Pacotes instalados?
conda list | grep airflow
conda list | grep pandas
```

### 9.2 Verificar Docker

```bash
# Todos os containers rodando?
docker-compose ps

# Ver logs se algum estiver com problema
docker-compose logs <nome_do_container>
```

### 9.3 Acessar cada serviÃ§o

âœ… **Airflow**: http://localhost:8080 (airflow/airflow)
âœ… **Label Studio**: http://localhost:8001 (label_ops@gmail.com/dataops@123)
âœ… **MinIO**: http://localhost:9001 (seu MINIO_ACCESS_KEY / MINIO_SECRET_KEY)
âœ… **Streamlit**: http://localhost:8501

---

## ğŸ¯ Parte 10: Executar Pipeline Pela Primeira Vez

### OpÃ§Ã£o A: Via Airflow (Recomendado)

1. **Acesse Airflow**: http://localhost:8080
2. **Login**: airflow / airflow
3. **Ative a DAG**: `00_event_driven_ingestion`
4. **Trigger manualmente**: Clique no â–¶ï¸
5. **Acompanhe execuÃ§Ã£o**: Veja tasks sendo executadas

### OpÃ§Ã£o B: Executar Scripts Localmente

```bash
# Certifique-se de que o ambiente conda estÃ¡ ativado
conda activate dataops

# Executar pipeline completo
python -m scripts_pipeline.clean_buckets
python -m scripts_pipeline.insert_bronze
python -m scripts_pipeline.transform_silver
python -m scripts_pipeline.aggregate_gold

# Verificar diagnÃ³stico
python diagnose_data_flow.py

# Executar dashboard para visualizar os dados
streamlit run streamlit\dashboard.py
```

**SaÃ­da esperada do pipeline**:
```
â„¹ï¸  Detectado execuÃ§Ã£o local. Usando endpoint: localhost:9000

ğŸ·ï¸  Extraindo labels NER...

   [EXTRAÃDO] cliente: 'joÃ£o silva'
   [EXTRAÃDO] valor: '150.50'

âœ… Pipeline executado com sucesso!
```

**SaÃ­da esperada do Streamlit**:
```
You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
```

> **ğŸ’¡ IMPORTANTE**: O comando `streamlit run` deve ser executado APÃ“S os dados subirem para a camada Gold. O dashboard ficarÃ¡ rodando continuamente - pressione Ctrl+C para parar.

---

## ğŸ“Š Parte 11: Visualizar no Dashboard

### OpÃ§Ã£o A: Dashboard no Docker (AutomÃ¡tico)

Se vocÃª estÃ¡ usando Docker, o dashboard jÃ¡ estÃ¡ rodando automaticamente:
```
http://localhost:8501
```

### OpÃ§Ã£o B: Dashboard Local (ExecuÃ§Ã£o Manual)

Se vocÃª executou o pipeline localmente (fora do Docker), apÃ³s os dados subirem para a camada Gold, execute:

```bash
# Certifique-se de que o ambiente conda estÃ¡ ativado
conda activate dataops

# Execute o dashboard Streamlit
streamlit run streamlit\dashboard.py
```

**SaÃ­da esperada**:
```
You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

**Acesse**: http://localhost:8501

**VocÃª deve ver**:
- âœ… KPIs agregados
- âœ… Tabelas com dados
- âœ… GrÃ¡ficos Plotly
- âœ… Dados em tempo real

> **ğŸ’¡ IMPORTANTE**: O dashboard se conecta ao MinIO para ler os dados da camada Gold. Certifique-se de que o MinIO estÃ¡ rodando (via Docker ou localmente).

---

## ğŸ› Troubleshooting

### Problema 1: Conda nÃ£o reconhecido

**Sintoma**: `conda: command not found`

**SoluÃ§Ã£o**:
```bash
# Windows: Adicionar ao PATH manualmente
# Painel de Controle > Sistema > VariÃ¡veis de Ambiente
# Adicionar: C:\Users\<usuario>\miniconda3\Scripts

# Ou reabrir terminal apÃ³s instalaÃ§Ã£o
```

### Problema 2: UV nÃ£o instala dependÃªncias

**Sintoma**: Erro ao executar `uv sync`

**SoluÃ§Ã£o**:
```bash
# Usar pip tradicional
cd enviroments
pip install -e .
```

### Problema 3: Docker nÃ£o inicia

**Sintoma**: Containers ficam em "Exited"

**SoluÃ§Ã£o**:
```bash
# Ver logs
docker-compose logs <container_name>

# Reiniciar Docker Desktop
# Reexecutar
docker-compose down
docker-compose up -d
```

### Problema 4: Python 3.10 nÃ£o disponÃ­vel

**Sintoma**: `PackageNotFoundError: python=3.10`

**SoluÃ§Ã£o**:
```bash
# Atualizar conda
conda update conda

# Ou usar Python 3.11 (tambÃ©m funciona)
conda create -n dataops python=3.11 -y
```

---

## ğŸ“ Comandos Ãšteis

### Gerenciar Ambiente Conda

```bash
# Ativar ambiente
conda activate dataops

# Desativar ambiente
conda deactivate

# Listar ambientes
conda env list

# Remover ambiente
conda env remove -n dataops

# Exportar ambiente
conda env export > environment.yml

# Criar ambiente de um arquivo
conda env create -f environment.yml
```

### Gerenciar DependÃªncias com UV

```bash
# Adicionar nova dependÃªncia
cd enviroments
uv add nome_do_pacote

# Remover dependÃªncia
uv remove nome_do_pacote

# Atualizar todas as dependÃªncias
uv sync --upgrade

# Ver dependÃªncias instaladas
uv pip list
```

### Gerenciar Docker

```bash
# Parar containers
docker-compose stop

# Parar e remover containers
docker-compose down

# Ver logs
docker-compose logs -f

# Reiniciar um serviÃ§o
docker-compose restart <service_name>

# Rebuild completo
docker-compose build --no-cache
docker-compose up -d
```

---

## âœ… Checklist Final

**InstalaÃ§Ã£o Base**:
- [ ] Conda instalado e funcionando
- [ ] Ambiente `dataops` criado com Python 3.10
- [ ] UV instalado e funcionando
- [ ] Docker + Docker Compose instalados

**DependÃªncias**:
- [ ] DependÃªncias do Python instaladas (via uv sync)
- [ ] Airflow, Pandas, MinIO SDK verificados
- [ ] Streamlit funcionando

**ConfiguraÃ§Ã£o**:
- [ ] .env criado e preenchido
- [ ] Legacy Token do Label Studio obtido
- [ ] Containers Docker todos "healthy"

**Funcionalidade**:
- [ ] Todos os serviÃ§os acessÃ­veis
- [ ] Pipeline executa sem erros
- [ ] Dashboard mostra dados

---

## ğŸ“ PrÃ³ximos Passos

Agora que seu ambiente estÃ¡ completo:

1. **Leia a documentaÃ§Ã£o completa**: [SETUP_COMPLETO.md](SETUP_COMPLETO.md)
2. **Execute o pipeline**: Siga [PROXIMO_TESTE.md](PROXIMO_TESTE.md)
3. **Explore o cÃ³digo**: Veja [VISAO_GERAL_PROJETO.md](VISAO_GERAL_PROJETO.md)

---

## ğŸ“š ReferÃªncias

- **Conda**: https://docs.conda.io/
- **UV**: https://github.com/astral-sh/uv
- **Docker**: https://docs.docker.com/
- **Airflow**: https://airflow.apache.org/docs/
- **Label Studio**: https://labelstud.io/guide/

---

**Pronto!** ğŸ‰ Seu ambiente estÃ¡ 100% configurado e pronto para uso!
