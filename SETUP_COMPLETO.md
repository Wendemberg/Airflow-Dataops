# üöÄ Setup Completo - Guia Passo a Passo

## üìã Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

- ‚úÖ **Docker** (vers√£o 20.10 ou superior)
- ‚úÖ **Docker Compose** (vers√£o 1.29 ou superior)
- ‚úÖ **Git** (para clonar o reposit√≥rio)
- ‚úÖ **Python 3.9+** (apenas se for executar scripts localmente)

### Verificar Instala√ß√£o

```bash
# Verificar Docker
docker --version
# Esperado: Docker version 20.10.x ou superior

# Verificar Docker Compose
docker-compose --version
# Esperado: docker-compose version 1.29.x ou superior

# Verificar Python (opcional)
python --version
# Esperado: Python 3.9.x ou superior
```

---

## üì• Passo 1: Clonar o Reposit√≥rio

```bash
# Clone o projeto
git clone <URL_DO_REPOSITORIO>

# Entre no diret√≥rio
cd Dataops
```

---

## üîê Passo 2: Configurar Vari√°veis de Ambiente

### 2.1 Criar arquivo .env

```bash
# Copiar o template
cp .env.example .env
```

### 2.2 Editar o arquivo .env

Abra o arquivo `.env` com seu editor favorito:

```bash
# Windows
notepad .env

# Linux/Mac
nano .env
# ou
vim .env
```

### 2.3 Preencher as credenciais

**IMPORTANTE**: Preencha com valores SEGUROS, n√£o use os exemplos abaixo em produ√ß√£o!

```env
# ========================================
# MinIO Configuration
# ========================================
MINIO_ACCESS_KEY=admin_dataops
MINIO_SECRET_KEY=SenhaSegura123!MinIO

# ========================================
# Label Studio Configuration
# ========================================
LABELSTUDIO_TOKEN=seu_token_aqui  # ‚¨ÖÔ∏è Voc√™ vai obter isso no Passo 4
LABELSTUDIO_PROJECT=4

# ========================================
# Airflow Configuration
# ========================================
AIRFLOW_UID=50000
```

> **üí° IMPORTANTE**: Deixe `LABELSTUDIO_TOKEN` vazio por enquanto. Voc√™ vai preencher no Passo 4.

---

## üê≥ Passo 3: Iniciar os Containers Docker

### 3.1 Build das imagens

```bash
# Build de todas as imagens
docker-compose build

# Isso pode demorar 5-10 minutos na primeira vez
```

### 3.2 Iniciar os servi√ßos

```bash
# Iniciar todos os containers em background
docker-compose up -d

# Acompanhar logs (opcional)
docker-compose logs -f
```

### 3.3 Verificar status dos containers

```bash
# Verificar se todos est√£o rodando
docker-compose ps
```

**Esperado**:
```
NAME                    STATUS              PORTS
airflow-webserver       Up (healthy)        0.0.0.0:8080->8080/tcp
airflow-scheduler       Up (healthy)
airflow-triggerer       Up (healthy)
minio                   Up (healthy)        0.0.0.0:9000->9000/tcp, 0.0.0.0:9001->9001/tcp
label-studio            Up (healthy)        0.0.0.0:8001->8080/tcp
streamlit-dashboard     Up (healthy)        0.0.0.0:8501->8501/tcp
```

> **‚è±Ô∏è Aguarde**: Pode demorar 2-3 minutos at√© todos os containers ficarem "healthy"

---

## üè∑Ô∏è Passo 4: Configurar Label Studio e Obter Token LEGACY

### 4.1 Acessar Label Studio

Abra seu navegador e acesse:
```
http://localhost:8001
```

### 4.2 Criar Conta no Primeiro Acesso

**‚ö†Ô∏è IMPORTANTE**: No primeiro acesso, voc√™ precisa criar uma conta.

#### Passo a passo:

1. **Acesse**: http://localhost:8001
2. **Clique em "Sign Up"** (se aparecer tela de login)
3. **Preencha o formul√°rio de cadastro**:
   - **Email**: `label_ops@gmail.com`
   - **Password**: `dataops@123`
   - **Confirm Password**: `dataops@123`
4. **Clique em "Create Account"**

> **üí° NOTA**: Se o Label Studio j√° tiver sido inicializado anteriormente e voc√™ vir uma tela de login, use as credenciais padr√£o:
> - **Email**: `admin@localhost.com`
> - **Senha**: `123456`
>
> Ou use as credenciais que voc√™ criou: `label_ops@gmail.com` / `dataops@123`

### 4.3 Configurar Legacy Token (IMPORTANTE!)

**‚ö†Ô∏è ATEN√á√ÉO**: O pipeline precisa do **LEGACY TOKEN**, n√£o do Access Token normal!

#### Passo a passo para configurar e obter o Legacy Token:

**Parte A: Habilitar Legacy Tokens (evitar expira√ß√£o)**

1. **No Label Studio, clique em "Organization"** (menu lateral esquerdo)
2. **Clique em "API Tokens Settings"**
3. **Desmarque todas as flags EXCETO "Legacy tokens"**
   - ‚úÖ Deixe APENAS "Legacy tokens" marcado
   - ‚ùå Desmarque as outras op√ß√µes (isso evita que o token expire)
4. **Clique em "Save"**

**Parte B: Gerar/Copiar o Legacy Token**

1. **Clique no √≠cone do usu√°rio** (canto superior direito)
2. **Clique em "Account & Settings"**
3. **Role at√© a se√ß√£o "Access Token"**
4. **Procure por "Legacy API Token"** ou **"API Token (Legacy)"**
5. **Copie o token** (algo como: `a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0`)

> **üí° IMPORTANTE**:
> - A configura√ß√£o em "Organization > API Tokens Settings" garante que o token n√£o expire
> - Deixar SOMENTE a flag "Legacy tokens" ativa √© FUNDAMENTAL
> - N√£o use o "Access Token" (JWT) - ele n√£o funciona com este pipeline
> - O Legacy Token tem formato: 40 caracteres hexadecimais

#### Imagem de refer√™ncia:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Account & Settings                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ...                                    ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ üîë Access Token                        ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Legacy API Token (deprecated)      ‚îÇ ‚îÇ
‚îÇ ‚îÇ a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6... ‚îÇ ‚îÇ ‚¨ÖÔ∏è COPIE ESTE!
‚îÇ ‚îÇ [Copy]                             ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.4 Atualizar .env com o Token

Edite o arquivo `.env` e cole o token:

```bash
# Editar .env
notepad .env  # Windows
nano .env     # Linux/Mac
```

Atualize a linha:
```env
LABELSTUDIO_TOKEN=a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0  # ‚¨ÖÔ∏è Cole seu token aqui
```

Salve o arquivo.

### 4.5 Reiniciar containers para aplicar o token

```bash
# Reiniciar para ler novo .env
docker-compose restart airflow-scheduler
docker-compose restart airflow-webserver
docker-compose restart streamlit
```

---

## üìä Passo 5: Criar Projeto no Label Studio (se necess√°rio)

Se voc√™ n√£o tiver o projeto ID 4, crie um novo:

### 5.1 Criar novo projeto

1. No Label Studio, clique em **"Create Project"**
2. Nome: `DataOps NER Pipeline`
3. Em **"Labeling Setup"**, escolha **"Named Entity Recognition"**
4. Configure os labels:
   - `cliente`
   - `produto`
   - `quantidade`
   - `valor`
   - `canal`
   - `forma_pagamento`
   - `status`
   - `cidade`
   - `avaliacao`
   - `data`
   - `sentimento`

5. Clique em **"Save"**

### 5.2 Obter ID do projeto

1. Acesse o projeto criado
2. Veja a URL no navegador:
   ```
   http://localhost:8001/projects/4/data
                                    ‚Üë
                              Este √© o ID
   ```
3. Atualize o `.env`:
   ```env
   LABELSTUDIO_PROJECT=4  # ‚¨ÖÔ∏è Coloque o ID correto
   ```

### 5.3 Importar Dataset do Projeto

**üìä Dataset dispon√≠vel em**:
```
https://drive.google.com/drive/folders/1WFkw54HojR1y_Io26_cNV5ni3888I2FZ?usp=sharing
```

**Como importar**:

1. **Baixe o dataset** do Google Drive
2. **No Label Studio**, abra o projeto (ID 4)
3. **Clique em "Import"**
4. **Selecione os arquivos JSON** baixados
5. **Clique em "Import"**

**Conte√∫do do dataset**:
- Transa√ß√µes comerciais com dados estruturados
- Anota√ß√µes NER j√° realizadas (cliente, produto, valor, quantidade, etc.)
- 950+ registros prontos para processamento

> **üí° NOTA**: Ap√≥s importar, o dataset estar√° pronto para ser processado pelo pipeline Airflow.

---

## ‚úÖ Passo 6: Verificar Servi√ßos

Acesse cada servi√ßo para verificar se est√° funcionando:

### 6.1 Airflow
```
URL: http://localhost:8080
Login: airflow
Senha: airflow
```

**O que verificar**:
- [ ] Interface do Airflow carrega
- [ ] DAGs aparecem na lista
- [ ] Nenhum erro nos logs

### 6.2 MinIO Console
```
URL: http://localhost:9001
Login: <seu MINIO_ACCESS_KEY do .env>
Senha: <seu MINIO_SECRET_KEY do .env>
```

**O que verificar**:
- [ ] Interface do MinIO carrega
- [ ] Buckets `bronze`, `silver`, `gold` e `inbox` existem

### 6.3 Label Studio
```
URL: http://localhost:8001
Login: label_ops@gmail.com
Senha: dataops@123
```

> **Ou se usou as credenciais padr√£o**: admin@localhost.com / 123456

**O que verificar**:
- [ ] Interface carrega
- [ ] Projeto aparece
- [ ] Token foi copiado corretamente

### 6.4 Streamlit Dashboard
```
URL: http://localhost:8501
(sem autentica√ß√£o)
```

**O que verificar**:
- [ ] Dashboard carrega
- [ ] Pode estar vazio se ainda n√£o houver dados (normal!)

---

## üéØ Passo 7: Executar Pipeline pela Primeira Vez

### Op√ß√£o A: Executar via Airflow (Recomendado)

1. **Acesse Airflow**: http://localhost:8080

2. **Ative as DAGs**:
   - Localize `00_event_driven_ingestion`
   - Clique no toggle para ativar (fica azul)

3. **Trigger manual**:
   - Clique no √≠cone de "play" ‚ñ∂Ô∏è na DAG
   - Clique em "Trigger DAG"

4. **Acompanhe execu√ß√£o**:
   - Clique na DAG para ver detalhes
   - Veja as tasks sendo executadas em tempo real

### Op√ß√£o B: Executar Scripts Manualmente (para teste)

Se quiser testar localmente (fora do Docker):

```bash
# Instalar depend√™ncias Python localmente
pip install -r requirements.txt

# Executar pipeline passo a passo
python -m scripts_pipeline.clean_buckets       # Limpar buckets
python -m scripts_pipeline.insert_bronze       # Inserir dados
python -m scripts_pipeline.transform_silver    # Transformar
python -m scripts_pipeline.aggregate_gold      # Agregar

# Ver diagn√≥stico
python diagnose_data_flow.py
```

**Sa√≠da esperada no transform_silver.py**:
```
‚ÑπÔ∏è  Detectado execu√ß√£o local. Usando endpoint: localhost:9000

üè∑Ô∏è  Extraindo labels NER e padronizando...

REGISTRO 0:
   [DEBUG] Processando 1 anota√ß√£o(√µes)
   [DEBUG] Anota√ß√£o 0 tem 5 resultado(s)
      [EXTRA√çDO] cliente: 'jo√£o silva'
      [EXTRA√çDO] valor: '150.50'

üìä Resumo de dados extra√≠dos da API do Label Studio:

   üè∑Ô∏è  Estat√≠sticas de Extra√ß√£o NER:
      ‚Ä¢ Registros com algum NER: 950
      ‚Ä¢ Registros com 'cliente': 950
      ‚Ä¢ Registros com 'produto': 950
```

---

## üìä Passo 8: Visualizar Dados no Dashboard

### Op√ß√£o A: Via Docker (Autom√°tico)

Se estiver usando Docker, o dashboard j√° est√° rodando. Acesse:
```
http://localhost:8501
```

### Op√ß√£o B: Execu√ß√£o Local (Manual)

Se executou o pipeline localmente, ap√≥s os dados subirem para a camada Gold, execute:

```bash
# Ativar ambiente (se necess√°rio)
conda activate dataops

# Executar dashboard
streamlit run streamlit\dashboard.py
```

**Acesse**: http://localhost:8501

**Voc√™ deve ver**:
- ‚úÖ KPIs agregados (se houver dados)
- ‚úÖ Tabelas com registros
- ‚úÖ Gr√°ficos Plotly
- ‚úÖ Dados em tempo real

> **üí° Se o dashboard estiver vazio**: Execute o pipeline primeiro (Passo 7)
>
> **‚ö†Ô∏è IMPORTANTE**: O dashboard requer que o MinIO esteja rodando para acessar os dados da camada Gold

---

## üêõ Troubleshooting - Problemas Comuns

### Problema 1: Container n√£o inicia

**Sintoma**: `docker-compose ps` mostra container com status "Exited"

**Solu√ß√£o**:
```bash
# Ver logs do container com problema
docker-compose logs <nome_do_container>

# Exemplo:
docker-compose logs label-studio
docker-compose logs minio
```

### Problema 2: "Failed to resolve 'minio'"

**Sintoma**: Erro ao executar scripts localmente

**Solu√ß√£o**:
- ‚úÖ J√° est√° corrigido! O sistema detecta automaticamente se est√° rodando local ou Docker
- Se ainda ocorrer, certifique que Docker est√° rodando: `docker ps`

### Problema 3: Label Studio n√£o aceita token

**Sintoma**: Erro 401 Unauthorized

**Solu√ß√£o**:
1. Certifique que est√° usando **Legacy Token**, n√£o Access Token
2. Verifique se copiou o token completo (40 caracteres)
3. N√£o deixe espa√ßos antes/depois do token no `.env`
4. Reinicie os containers: `docker-compose restart`

### Problema 4: Buckets MinIO n√£o existem

**Sintoma**: Erro "Bucket 'bronze' does not exist"

**Solu√ß√£o**:
```bash
# Reexecutar inicializa√ß√£o do MinIO
docker-compose restart minio-init

# Ver logs da inicializa√ß√£o
docker-compose logs minio-init
```

### Problema 5: Port j√° em uso

**Sintoma**: "Port 8080 is already allocated"

**Solu√ß√£o**:
```bash
# Parar processo que est√° usando a porta
# Windows:
netstat -ano | findstr :8080
taskkill /PID <PID> /F

# Linux/Mac:
lsof -i :8080
kill -9 <PID>

# Ou mudar porta no docker-compose.yml
```

### Problema 6: Credenciais incorretas

**Sintoma**: "Authentication failed"

**Solu√ß√£o**:
```bash
# Verificar se .env foi lido corretamente
docker-compose config | grep MINIO_ACCESS_KEY

# Se vazio, o .env n√£o foi lido
# Certifique que:
# 1. .env est√° na raiz do projeto
# 2. N√£o tem espa√ßos antes/depois do =
# 3. Reiniciou os containers
```

---

## üìö Comandos √öteis

### Gerenciamento de Containers

```bash
# Ver logs em tempo real
docker-compose logs -f

# Ver logs de um servi√ßo espec√≠fico
docker-compose logs -f streamlit

# Parar todos os containers
docker-compose stop

# Parar e remover containers
docker-compose down

# Reiniciar um servi√ßo
docker-compose restart airflow-scheduler

# Executar comando dentro de um container
docker-compose exec streamlit bash
```

### Limpeza e Reset

```bash
# Parar e remover tudo (CUIDADO: deleta dados!)
docker-compose down -v

# Rebuild completo
docker-compose build --no-cache
docker-compose up -d
```

### Monitoramento

```bash
# Ver uso de recursos
docker stats

# Ver status de sa√∫de
docker-compose ps

# Ver networks
docker network ls
docker network inspect dataops_dataops-network
```

---

## ‚úÖ Checklist Final

Antes de considerar o setup completo, verifique:

**Containers**:
- [ ] Todos containers est√£o "Up (healthy)"
- [ ] Nenhum container em status "Exited"

**Configura√ß√£o**:
- [ ] .env criado com credenciais preenchidas
- [ ] LABELSTUDIO_TOKEN √© o Legacy Token (40 caracteres)
- [ ] LABELSTUDIO_PROJECT corresponde ao ID correto

**Acesso aos Servi√ßos**:
- [ ] Airflow acess√≠vel em http://localhost:8080
- [ ] MinIO acess√≠vel em http://localhost:9001
- [ ] Label Studio acess√≠vel em http://localhost:8001
- [ ] Streamlit acess√≠vel em http://localhost:8501

**Funcionalidade**:
- [ ] DAG aparece no Airflow
- [ ] Buckets existem no MinIO (bronze, silver, gold, inbox)
- [ ] Projeto existe no Label Studio
- [ ] Pipeline executa sem erros

**Testes**:
- [ ] Executou pipeline manualmente (Passo 7)
- [ ] Dados aparecem no dashboard
- [ ] Logs n√£o mostram erros cr√≠ticos

---

## üéì Pr√≥ximos Passos

Agora que o setup est√° completo:

1. **Adicione dados** ao Label Studio (projeto 4)
2. **Anote os dados** com as labels NER
3. **Execute o pipeline** via Airflow
4. **Visualize resultados** no dashboard

Para mais informa√ß√µes:
- **[COMECE_AQUI.md](COMECE_AQUI.md)** - Quick start
- **[DOCKER_COMPOSE_SETUP.md](DOCKER_COMPOSE_SETUP.md)** - Docker detalhado
- **[PROXIMO_TESTE.md](PROXIMO_TESTE.md)** - Testes completos

---

## üìû Suporte

Se encontrar problemas:

1. Consulte a se√ß√£o **Troubleshooting** acima
2. Verifique os logs: `docker-compose logs -f`
3. Veja documenta√ß√£o espec√≠fica em `docs/`

---

**Pronto!** üéâ Seu ambiente DataOps est√° configurado e funcionando!
